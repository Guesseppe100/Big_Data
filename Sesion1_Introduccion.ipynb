{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jazaineam1/BigData2023_2/blob/main/Cuadernos/Sesion1_Introducci%C3%B3n.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2DZSfsQL3Bm"
      },
      "source": [
        "# ***Introducci√≥n a Big Data e ingesta de datos en python***\n",
        "\n",
        "## ***Universidad Central***\n",
        ">## **Facultad de Ingenier√≠a y Ciencias B√°sicas.**\n",
        ">## ***Maestr√≠a en anal√≠tica de datos***\n",
        "![Universidad Central](images/1.png)\n",
        "\n",
        "\n",
        ">## ***Big Data.***\n",
        ">## ***Docente: Antonino Zainea Maya.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsXqiID8VZtW"
      },
      "source": [
        "## Parte 1\n",
        "\n",
        "### Introducci√≥n\n",
        "\n",
        "En el mundo digital actual, es importante entender la cantidad de datos que las plataformas en l√≠nea recopilan sobre nosotros y c√≥mo esta informaci√≥n se utiliza para personalizar servicios y anuncios. A continuaci√≥n, exploramos algunas de las principales empresas y la informaci√≥n que pueden recopilar:\n",
        "\n",
        "1. Google y su Recopilaci√≥n de Datos:\n",
        "\n",
        "Al utilizar servicios de Google como Gmail, es esencial leer detenidamente la pol√≠tica de privacidad para comprender qu√© datos estamos autorizando compartir. Google rastrea nuestras b√∫squedas, ubicaciones y viajes, y utiliza estos datos para dirigir anuncios espec√≠ficos hacia nosotros.\n",
        "\n",
        "2. Facebook y su Conocimiento Detallado:\n",
        "\n",
        "Facebook sabe detalles sobre nuestras relaciones, intereses y actividades, lo que puede influir en los anuncios que vemos. Incluso puede predecir el deterioro de relaciones bas√°ndose en patrones en la plataforma. La capacidad de la plataforma para inferir rasgos emocionales a trav√©s de las interacciones tambi√©n es notable.\n",
        "\n",
        "3. Twitter y las Implicaciones Personales:\n",
        "\n",
        "Twitter tambi√©n tiene la capacidad de inferir nuestra estabilidad emocional bas√°ndose en nuestras interacciones y publicaciones. Algunas empresas incluso utilizan an√°lisis de redes sociales durante los procesos de selecci√≥n.\n",
        "\n",
        "4. Apple y la Continuidad de la Conexi√≥n:\n",
        "\n",
        "Los iPhones est√°n dise√±ados de manera que la bater√≠a no se pueda extraer, lo que puede llevar a que el dispositivo siempre est√© conectado. Esto ha llevado a especulaciones sobre si los datos se transmiten incluso cuando el tel√©fono est√° apagado o sin bater√≠a.\n",
        "\n",
        "5. YouTube y Amazon: Personalizaci√≥n y Recomendaciones:\n",
        "\n",
        "Plataformas como YouTube y Amazon recopilan informaci√≥n sobre los videos que vemos y las compras que realizamos, respectivamente. Esta informaci√≥n se utiliza para recomendaciones personalizadas, lo que contribuye a la experiencia del usuario."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ht6TMsECR_ZH"
      },
      "source": [
        "\n",
        "<span class=\"hljs-tag\"><img src=\"https://cdn.statcdn.com/Infographic/images/normal/17539.jpeg\" width=\"580\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68V2FQOZZwTu"
      },
      "source": [
        "La actual era, a menudo denominada \"era de la informaci√≥n\" o \"era digital\", se caracteriza por la abundancia de datos y la r√°pida evoluci√≥n de la tecnolog√≠a de la informaci√≥n. En esta era, la industria ha experimentado una transformaci√≥n significativa en la forma en que opera y toma decisiones debido al acceso y la disponibilidad de grandes vol√∫menes de informaci√≥n. Aqu√≠ hay algunas razones clave por las cuales el manejo de grandes vol√∫menes de informaci√≥n es crucial en la industria en esta era:\n",
        "\n",
        "1. **Toma de decisiones informadas:** üßêüìä Las organizaciones pueden tomar decisiones m√°s informadas y estrat√©gicas al analizar grandes conjuntos de datos. Esto les permite comprender mejor el mercado, los patrones de consumo, las preferencias del cliente y las tendencias emergentes. La toma de decisiones basada en datos es esencial para mantenerse competitivo en un entorno empresarial en constante cambio.\n",
        "\n",
        "2. **Personalizaci√≥n y segmentaci√≥n:** üéØüë• Con acceso a grandes cantidades de datos, las empresas pueden personalizar sus productos y servicios de acuerdo con las necesidades y preferencias individuales de los clientes. Esto les permite dirigirse a segmentos espec√≠ficos de la poblaci√≥n de manera m√°s efectiva, mejorando as√≠ la experiencia del cliente y aumentando la lealtad.\n",
        "\n",
        "3. **Optimizaci√≥n de procesos:** ‚öôÔ∏èüìà El an√°lisis de grandes vol√∫menes de datos puede revelar ineficiencias y √°reas de mejora en los procesos empresariales. Al identificar estos puntos d√©biles, las organizaciones pueden optimizar sus operaciones, reducir costos y mejorar la eficiencia en general.\n",
        "\n",
        "4. **Innovaci√≥n:** üí°üöÄ La exploraci√≥n de grandes cantidades de datos puede conducir a descubrimientos y patrones inesperados que pueden generar nuevas ideas y oportunidades de innovaci√≥n. Al identificar correlaciones y relaciones que no eran evidentes anteriormente, las empresas pueden desarrollar productos y servicios innovadores.\n",
        "\n",
        "5. **Predicci√≥n y prevenci√≥n:** üîÆüïµÔ∏è‚Äç‚ôÇÔ∏è Mediante el an√°lisis de datos hist√≥ricos y en tiempo real, las empresas pueden predecir tendencias futuras y riesgos potenciales. Esto es especialmente valioso en sectores como la salud, la seguridad cibern√©tica y la gesti√≥n de la cadena de suministro, donde la anticipaci√≥n de problemas puede marcar la diferencia.\n",
        "\n",
        "6. **Mejora de la experiencia del cliente:** üõçÔ∏èüë§ Las empresas pueden utilizar datos para comprender mejor el viaje del cliente y mejorar su experiencia en todas las etapas. Esto incluye desde la adquisici√≥n inicial hasta la retenci√≥n y el servicio postventa, lo que conduce a relaciones m√°s s√≥lidas con los clientes.\n",
        "\n",
        "7. **Investigaci√≥n y desarrollo:** üî¨üíº En industrias como la farmac√©utica y la tecnolog√≠a, el an√°lisis de grandes conjuntos de datos puede acelerar la investigaci√≥n y el desarrollo al identificar patrones y relaciones en la informaci√≥n recopilada.\n",
        "\n",
        "8. **Competitividad:** üèÜüìà Aquellas organizaciones que pueden aprovechar eficazmente grandes vol√∫menes de datos tienen una ventaja competitiva en el mercado. La capacidad de adaptarse y responder a los cambios en funci√≥n de la informaci√≥n en tiempo real puede marcar una gran diferencia en la capacidad de una empresa para mantenerse relevante y competitiva.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AT_HuPOEPZJz"
      },
      "source": [
        "![](https://pbs.twimg.com/media/EFz4Xl2XUAA4G8z?format=jpg&name=900x900)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zX6Lqb3ta0kV"
      },
      "source": [
        "El an√°lisis de conjuntos de datos de Big Data es un esfuerzo interdisciplinario que combina matem√°ticas, estad√≠sticas, ciencias de la computaci√≥n y experiencia en la materia. Esta mezcla de conjuntos de habilidades y perspectivas ha generado cierta confusi√≥n sobre lo que comprende el campo del Big Data y su an√°lisis, ya que la respuesta que se recibe depender√° de la perspectiva de quien responda a la pregunta. Los l√≠mites de lo que constituye un problema de Big Data tambi√©n est√°n cambiando debido al paisaje en constante cambio y avance de la tecnolog√≠a de software y hardware. Esto se debe al hecho de que la definici√≥n de Big Data tiene en cuenta el impacto de las caracter√≠sticas de los datos en el dise√±o del entorno de soluci√≥n en s√≠ mismo. Hace treinta a√±os, un gigabyte de datos pod√≠a representar un problema de Big Data y requerir recursos inform√°ticos especiales. Ahora, los gigabytes de datos son comunes y se pueden transmitir, procesar y almacenar f√°cilmente en dispositivos orientados al consumidor.\n",
        "\n",
        "Los datos dentro de los entornos de Big Data generalmente se acumulan al ser recopilados dentro de la empresa a trav√©s de aplicaciones, sensores y fuentes externas. Los datos procesados por una soluci√≥n de Big Data pueden ser utilizados directamente por las aplicaciones empresariales o pueden ser alimentados en un almac√©n de datos para enriquecer los datos existentes all√≠. Los resultados obtenidos a trav√©s del procesamiento de Big Data pueden llevar a una amplia gama de conocimientos y beneficios, como:\n",
        "\n",
        "\n",
        "\n",
        "- Optimizaci√≥n operativa üîÑüìä\n",
        "- Inteligencia accionable üß†üí°\n",
        "- Identificaci√≥n de nuevos mercados üåçüîç\n",
        "- Predicciones precisas üéØüîÆ\n",
        "- Detecci√≥n de fallas y fraudes ‚ö†Ô∏èüïµÔ∏è‚Äç‚ôÇÔ∏è\n",
        "- Registros m√°s detallados üìùüîç\n",
        "- Mejora en la toma de decisiones üìàü§ù\n",
        "- Descubrimientos cient√≠ficos üî¨üß™\n",
        "\n",
        "\n",
        "\n",
        "Evidentemente, las aplicaciones y los beneficios potenciales del Big Data son amplios. Sin embargo, existen numerosos problemas que deben considerarse al adoptar enfoques de an√°lisis de Big Data. Estos problemas deben entenderse y ponderarse frente a los beneficios anticipados para que se puedan generar decisiones y planes informados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EZKoeSTb_e1"
      },
      "source": [
        "### **Algunos conceptos importantes**\n",
        "\n",
        "**On-Premise:**\n",
        "- **Almacenamiento local:** En una soluci√≥n \"on-premise\", los datos se almacenan en servidores y sistemas que est√°n f√≠sicamente ubicados en las instalaciones de la organizaci√≥n.\n",
        "- **Control total:** La organizaci√≥n tiene un control completo sobre la infraestructura, los servidores y el entorno en el que se encuentran los datos.\n",
        "- **Seguridad y privacidad:** La seguridad depende de la infraestructura y medidas de seguridad implementadas por la organizaci√≥n, lo que puede requerir inversiones significativas en t√©rminos de seguridad cibern√©tica y recursos humanos.\n",
        "- **Costos iniciales:** Se requiere una inversi√≥n inicial en hardware, servidores, infraestructura y personal para gestionar y mantener los sistemas.\n",
        "- **Escalabilidad limitada:** La escalabilidad puede ser m√°s complicada y costosa, ya que se deben adquirir y configurar nuevos equipos f√≠sicos a medida que crecen los requisitos de datos.\n",
        "- **Acceso local:** El acceso a los datos suele limitarse a la red interna de la organizaci√≥n y puede requerir conexiones VPN para acceder de forma segura desde ubicaciones remotas.\n",
        "\n",
        "**Data Cloud (Nube de Datos):**\n",
        "- **Almacenamiento en la nube:** En una soluci√≥n de \"data cloud\", los datos se almacenan en servidores remotos y gestionados por proveedores de servicios en la nube.\n",
        "- **Infraestructura gestionada:** La organizaci√≥n no es responsable de mantener la infraestructura f√≠sica. El proveedor de la nube se encarga de la administraci√≥n y el mantenimiento.\n",
        "- **Seguridad y privacidad:** Los proveedores de la nube ofrecen medidas de seguridad robustas y certificaciones para proteger los datos. Sin embargo, la confianza en la seguridad de la nube implica ceder cierto nivel de control a terceros.\n",
        "- **Costos escalonados:** Los costos suelen ser operativos en lugar de iniciales, con modelos de pago por uso. Puede ser m√°s rentable a largo plazo, especialmente para empresas que experimentan cambios en sus necesidades de almacenamiento y c√≥mputo.\n",
        "- **Escalabilidad flexible:** La nube permite escalar f√°cilmente los recursos seg√∫n las necesidades cambiantes, ya que los proveedores pueden asignar recursos adicionales de manera r√°pida y eficiente.\n",
        "- **Acceso remoto:** Los datos pueden accederse desde cualquier ubicaci√≥n con conexi√≥n a Internet, lo que facilita el trabajo remoto y la colaboraci√≥n.\n",
        "\n",
        "La elecci√≥n entre \"on-premise\" y \"data cloud\" depende de los objetivos, recursos y necesidades de seguridad de una organizaci√≥n. Las soluciones \"on-premise\" brindan un mayor control pero requieren inversiones significativas, mientras que las soluciones en la nube ofrecen flexibilidad y escalabilidad, a expensas de ceder cierto control sobre la infraestructura a terceros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZvfnz6UlWTP"
      },
      "source": [
        "\n",
        "\n",
        "<span class=\"hljs-tag\"><img src=\"https://edteam-media.s3.amazonaws.com/blogs/original/def59e91-b472-40dd-b9c4-cda7f79a3515.png\" width=\"580\">\n",
        "\n",
        "## Las Mejores Empresas de Cloud Computing\n",
        "\n",
        "Lamejores empresas de Cloud Computing, ideales para ser contratadas debido a su eficiencia y competitividad en t√©rminos de computaci√≥n en la nube, procesamiento y an√°lisis de datos. Las herramientas y servicios que ofrecen son fundamentales para optimizar las operaciones empresariales de manera eficiente.\n",
        "\n",
        "1.  [**Amazon Web Services (AWS)** üåêüîß](https://aws.amazon.com/es/)\n",
        "   Amazon Web Services es una plataforma de Cloud Computing gestionada por Amazon. Es la plataforma m√°s grande y ampliamente utilizada en todo el mundo, ofreciendo una variedad de herramientas y servicios que facilitan la administraci√≥n de operaciones empresariales de manera efectiva. Algunas de estas herramientas incluyen:\n",
        "   \n",
        "   - Amazon Elastic Compute Cloud\n",
        "   - Amazon Simple Storage Service\n",
        "   - Amazon Relational Database Service\n",
        "   - Amazon Virtual Private Cloud\n",
        "   - Amazon Lambda\n",
        "   - Amazon Elastic Block Store\n",
        "\n",
        "2. [**Microsoft Azure** ‚òÅÔ∏èüîç](https://azure.microsoft.com/es-es)\n",
        "   Microsoft Azure es la plataforma de Cloud Computing de Microsoft. Ofrece servicios de computaci√≥n, almacenamiento, an√°lisis de datos y aprendizaje autom√°tico, entre otros. Destacan servicios como:\n",
        "   \n",
        "   - Azure Virtual Machines\n",
        "   - Azure Storage\n",
        "   - Azure SQL Database\n",
        "   - Azure App Service\n",
        "   - Azure Cosmos DB\n",
        "\n",
        "3. [**Google Cloud Platform (GCP)** ‚òÅÔ∏èüöÄ](https://cloud.google.com/?hl=es)\n",
        "   Google Cloud Platform es la soluci√≥n de Google, conocida por su disponibilidad, escalabilidad y precio competitivo. Ofrece una amplia gama de servicios, como:\n",
        "   \n",
        "   - Google Compute Engine\n",
        "   - Google Cloud Storage\n",
        "   - Google Cloud SQL\n",
        "   - Google BigQuery\n",
        "\n",
        "4. [**IBM Cloud** ‚òÅÔ∏èüîë](https://cloud.ibm.com/)\n",
        "   IBM Cloud ofrece una amplia gama de servicios, incluyendo almacenamiento, computaci√≥n, an√°lisis y servicios integrados con herramientas existentes de IBM. Algunos servicios destacados son:\n",
        "   \n",
        "   - IBM Watson Studio\n",
        "   - IBM Cloud Pak for Data\n",
        "   - IBM Cloud Pak for Security\n",
        "\n",
        "\n",
        "**Fuente:** [Tokio School](https://www.tokioschool.com/noticias/empresas-cloud-computing/)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUzploqznegq"
      },
      "source": [
        "![texto del v√≠nculo](https://i.blogs.es/282664/crecimiento-cloud-computing-1/1366_2000.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bja2W9P4oTCD"
      },
      "source": [
        "## ¬øQu√© es el Big Data?\n",
        "\n",
        "Para que un conjunto de datos sea considerado como Big Data, debe poseer una o m√°s caracter√≠sticas que requieran adaptaci√≥n en el dise√±o y la arquitectura de la soluci√≥n del entorno anal√≠tico. La mayor√≠a de estas caracter√≠sticas de los datos fueron identificadas inicialmente por Doug Laney a principios de 2001, cuando public√≥ un art√≠culo describiendo el impacto del volumen, la velocidad y la variedad de los datos de comercio electr√≥nico en los almacenes de datos empresariales. A esta lista se ha a√±adido la veracidad para tener en cuenta la relaci√≥n se√±al-ruido m√°s baja de los datos no estructurados en comparaci√≥n con las fuentes de datos estructurados. En √∫ltima instancia, el objetivo es realizar un an√°lisis de los datos de manera que se entreguen resultados de alta calidad de manera oportuna, lo que proporciona un valor √≥ptimo a la empresa.\n",
        "\n",
        "Esta secci√≥n explora las cinco caracter√≠sticas del Big Data que pueden utilizarse para diferenciar los datos categorizados como \"grandes\" de otras formas de datos. Las cinco caracter√≠sticas del Big Data  se conocen com√∫nmente como los Cinco V:\n",
        "- Volumen (Volume)\n",
        "- Velocidad (Velocity)\n",
        "- Variedad (Variety)\n",
        "- Veracidad (Veracity)\n",
        "- Valor (Value)\n",
        "\n",
        "<span class=\"hljs-tag\"><img src=\"https://datascience.uc.cl/images/las-5-v-bigdata.png\" width=\"480\">\n",
        "\n",
        "\n",
        "**Volumen**\n",
        "El volumen anticipado de datos que procesan las soluciones de Big Data es considerable y est√° en constante crecimiento. Los altos vol√∫menes de datos imponen demandas distintas en el almacenamiento y procesamiento de datos, as√≠ como procesos adicionales de preparaci√≥n, curaci√≥n y gesti√≥n de datos.\n",
        "\n",
        "Fuentes de datos t√≠picas que son responsables de generar altos vol√∫menes de datos pueden incluir:\n",
        "\n",
        "* transacciones en l√≠nea, como puntos de venta y banca\n",
        "* experimentos cient√≠ficos e investigaciones, como el Gran Colisionador de Hadrones y el telescopio Atacama Large Millimeter/Submillimeter Array\n",
        "* sensores, como sensores GPS, RFIDs, medidores inteligentes y telemetr√≠a\n",
        "* redes sociales, como Facebook y Twitter\n",
        "\n",
        "**Velocidad**\n",
        "En entornos de Big Data, los datos pueden llegar a velocidades r√°pidas y enormes conjuntos de datos pueden acumularse en per√≠odos de tiempo muy cortos. Desde el punto de vista de una empresa, la velocidad de los datos se traduce en el tiempo que lleva procesar los datos una vez que ingresan en el per√≠metro de la empresa. Lidiar con el r√°pido flujo de datos requiere que la empresa dise√±e soluciones de procesamiento de datos altamente el√°sticas y disponibles, as√≠ como capacidades de almacenamiento de datos correspondientes.\n",
        "\n",
        "Dependiendo de la fuente de datos, la velocidad no siempre puede ser alta. Por ejemplo, las im√°genes de resonancia magn√©tica (MRI) no se generan con tanta frecuencia como las entradas de registro de un servidor web con mucho tr√°fico. La velocidad de los datos cobra perspectiva al considerar que los siguientes vol√∫menes de datos pueden generarse f√°cilmente en un minuto dado: 350,000 tweets, 500 horas de metraje de video cargado en YouTube, 197 millones de correos electr√≥nicos y 330 GB de datos de sensores de un motor a reacci√≥n.\n",
        "\n",
        "\n",
        "**Variedad**\n",
        "La variedad de datos se refiere a los m√∫ltiples formatos y tipos de datos que deben ser compatibles con las soluciones de Big Data. La variedad de datos plantea desaf√≠os para las empresas en t√©rminos de integraci√≥n, transformaci√≥n, procesamiento y almacenamiento de datos.Dentro de la variedad se encuentran la clasificacion seg√∫n el tipo de  datos estructurados en forma de transacciones financieras, datos semi-estructurados en forma de correos electr√≥nicos y datos no estructurados en forma de im√°genes.\n",
        "\n",
        "**Veracidad**\n",
        "La veracidad se refiere a la calidad o fidelidad de los datos. Los datos que ingresan en entornos de Big Data deben ser evaluados en cuanto a su calidad, lo que puede llevar a actividades de procesamiento de datos para resolver datos inv√°lidos y eliminar el ruido. En relaci√≥n con la veracidad, los datos pueden ser parte de la se√±al o del ruido en un conjunto de datos. El ruido es data que no se puede convertir en informaci√≥n y, por lo tanto, no tiene valor, mientras que las se√±ales tienen valor y conducen a informaci√≥n significativa. Los datos con una alta relaci√≥n se√±al-ruido tienen m√°s veracidad que los datos con una relaci√≥n m√°s baja. Los datos que se adquieren de manera controlada, por ejemplo, a trav√©s de registros de clientes en l√≠nea, suelen contener menos ruido que los datos adquiridos a trav√©s de fuentes no controladas, como publicaciones en blogs. Por lo tanto, la relaci√≥n se√±al-ruido de los datos depende de la fuente de los datos y su tipo.\n",
        "\n",
        "\n",
        "**Valor**\n",
        "El valor se define como la utilidad de los datos para una empresa. La caracter√≠stica de valor est√° intuitivamente relacionada con la caracter√≠stica de veracidad en el sentido de que cuanto mayor sea la fidelidad de los datos, m√°s valor tendr√° para el negocio. El valor tambi√©n depende de cu√°nto tiempo lleva el procesamiento de datos, ya que los resultados del an√°lisis tienen una vida √∫til; por ejemplo, una cotizaci√≥n de acciones con 20 minutos de retraso tiene poco o ning√∫n valor para realizar una operaci√≥n en comparaci√≥n con una cotizaci√≥n que tiene 20 milisegundos de antig√ºedad.\n",
        "Como se demuestra, el valor y el tiempo est√°n inversamente relacionados. Cuanto m√°s tiempo se tarde en convertir los datos en informaci√≥n significativa, menos valor tendr√° para un negocio. Los resultados obsoletos inhiben la calidad y la velocidad de la toma de decisiones informadas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elJAgk80q9AC"
      },
      "source": [
        "Los datos generados por humanos y por m√°quinas pueden provenir de una variedad de fuentes y representarse en diversos formatos o tipos. A Continuaci√≥n veremos la variedad de tipos de datos que son procesados por las soluciones de Big Data. Los principales tipos de datos son:\n",
        "\n",
        "- Datos estructurados\n",
        "- Datos no estructurados\n",
        "- Datos semi-estructurados\n",
        "\n",
        "![texto del v√≠nculo](https://dgcloud.com.br/wp-content/uploads/2022/01/Estruturado-vs-Desestruturado.png)\n",
        "\n",
        "Estos tipos de datos se refieren a la organizaci√≥n interna de los datos y a veces se denominan formatos de datos. Aparte de estos tres tipos fundamentales de datos.\n",
        "\n",
        "**Datos Estructurados**\n",
        "\n",
        "Los datos estructurados se ajustan a un modelo de datos o esquema y a menudo se almacenan en forma de tablas. Se utilizan para capturar relaciones entre diferentes entidades y, por lo tanto, se almacenan principalmente en una base de datos relacional. Los datos estructurados son generados con frecuencia por aplicaciones empresariales y sistemas de informaci√≥n como los sistemas ERP y CRM. Debido a la abundancia de herramientas y bases de datos que admiten nativamente datos estructurados, rara vez requiere consideraci√≥n especial en cuanto a procesamiento o almacenamiento. Ejemplos de este tipo de datos incluyen transacciones bancarias, facturas y registros de clientes.\n",
        "\n",
        "* Ejemplo: Informaci√≥n de una base de datos de clientes que incluye nombres, direcciones, n√∫meros de tel√©fono y fechas de compra.\n",
        "\n",
        "* Formatos Comunes: Tablas en bases de datos relacionales (por ejemplo, SQL), hojas de c√°lculo (por ejemplo, Excel), archivos CSV (valores separados por comas).\n",
        "\n",
        "**Datos No Estructurados**\n",
        "\n",
        "Los datos que no se ajustan a un modelo de datos o esquema de datos se conocen como datos no estructurados. Se estima que los datos no estructurados representan el 80% de los datos dentro de cualquier empresa dada. Los datos no estructurados tienen una tasa de crecimiento m√°s r√°pida que los datos estructurados. Esta forma de datos puede ser tanto textual como binaria, y a menudo se transmite a trav√©s de archivos que son autosuficientes y no relacionales. Un archivo de texto puede contener el contenido de varios tweets o publicaciones de blogs. Los archivos binarios suelen ser archivos multimedia que contienen datos de im√°genes, audio o video. T√©cnicamente, tanto los archivos de texto como los binarios tienen una estructura definida por el formato del archivo en s√≠, pero este aspecto se pasa por alto y la noci√≥n de ser no estructurados se refiere al formato de los datos contenidos en el archivo en s√≠ mismo.\n",
        "\n",
        "* Ejemplo: Comentarios de clientes en una plataforma de redes sociales que expresan opiniones sobre un producto.\n",
        "\n",
        "* Formatos Comunes: Texto libre en comentarios, publicaciones de redes sociales, contenido de blogs, im√°genes, audio y video.\n",
        "\n",
        "**Datos Semi-Estructurados**\n",
        "\n",
        "Los datos semi-estructurados tienen un nivel definido de estructura y consistencia, pero no son de naturaleza relacional. En cambio, los datos semi-estructurados son jer√°rquicos o basados en gr√°ficos. Este tipo de datos com√∫nmente se almacena en archivos que contienen texto.Los archivos XML y JSON son formas comunes de datos semi-estructurados. Debido a la naturaleza textual de estos datos y su conformidad con alg√∫n nivel de estructura, son m√°s f√°ciles de procesar que los datos no estructurados.\n",
        "\n",
        "* Ejemplo: Informaci√≥n de productos en formato XML que incluye detalles de productos y atributos.\n",
        "\n",
        "* Formatos Comunes: Archivos XML (Lenguaje de Marcado Extensible) para datos jer√°rquicos, archivos JSON (Notaci√≥n de Objetos JavaScript) para datos basados en atributos, archivos HTML (Lenguaje de Marcado de Hipertexto) con metadatos y contenido estructurado.\n",
        "\n",
        "*Tomemos una pausa de  15 minutos*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-KdSHOFtRHB"
      },
      "source": [
        "## Parte 2\n",
        "\n",
        "### Manipulaci√≥n de datos en python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yf8gZmLWYDkh"
      },
      "source": [
        "En este apartado tendremos enfoque en la  tarea de manipulaci√≥n de datos en sus diversas formas: estructurados, no estructurados y semi-estructurados. Cada tipo de dato presenta desaf√≠os √∫nicos y oportunidades emocionantes en el mundo del an√°lisis y la toma de decisiones.\n",
        "\n",
        "Comenzaremos por adentrarnos en el mundo de los datos estructurados, que siguen un esquema definido y se almacenan en tablas. Aprenderemos c√≥mo utilizar herramientas como pandas en Python para organizar, filtrar y agregar datos, obteniendo informaci√≥n valiosa de conjuntos\n",
        "tabulares.\n",
        "\n",
        "#### **Datos estructurados**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "seEgoEWaYC61",
        "outputId": "2ea4ea7d-390b-419c-8ed6-5fbd768c072c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Nombre</th>\n",
              "      <th>Edad</th>\n",
              "      <th>Departamento</th>\n",
              "      <th>Salario</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ana</td>\n",
              "      <td>25</td>\n",
              "      <td>Ventas</td>\n",
              "      <td>50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Juan</td>\n",
              "      <td>30</td>\n",
              "      <td>TI</td>\n",
              "      <td>60000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Mar√≠a</td>\n",
              "      <td>28</td>\n",
              "      <td>RRHH</td>\n",
              "      <td>55000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Carlos</td>\n",
              "      <td>22</td>\n",
              "      <td>Ventas</td>\n",
              "      <td>45000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Elena</td>\n",
              "      <td>35</td>\n",
              "      <td>Finanzas</td>\n",
              "      <td>70000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Pedro</td>\n",
              "      <td>40</td>\n",
              "      <td>TI</td>\n",
              "      <td>75000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Laura</td>\n",
              "      <td>27</td>\n",
              "      <td>RRHH</td>\n",
              "      <td>52000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Sof√≠a</td>\n",
              "      <td>29</td>\n",
              "      <td>Finanzas</td>\n",
              "      <td>58000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Miguel</td>\n",
              "      <td>31</td>\n",
              "      <td>TI</td>\n",
              "      <td>62000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Luis</td>\n",
              "      <td>24</td>\n",
              "      <td>Ventas</td>\n",
              "      <td>48000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Nombre  Edad Departamento  Salario\n",
              "0     Ana    25       Ventas    50000\n",
              "1    Juan    30           TI    60000\n",
              "2   Mar√≠a    28         RRHH    55000\n",
              "3  Carlos    22       Ventas    45000\n",
              "4   Elena    35     Finanzas    70000\n",
              "5   Pedro    40           TI    75000\n",
              "6   Laura    27         RRHH    52000\n",
              "7   Sof√≠a    29     Finanzas    58000\n",
              "8  Miguel    31           TI    62000\n",
              "9    Luis    24       Ventas    48000"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Crear un diccionario con datos de ejemplo\n",
        "datos = {\n",
        "    'Nombre': ['Ana', 'Juan', 'Mar√≠a', 'Carlos', 'Elena', 'Pedro', 'Laura', 'Sof√≠a', 'Miguel', 'Luis'],\n",
        "    'Edad': [25, 30, 28, 22, 35, 40, 27, 29, 31, 24],\n",
        "    'Departamento': ['Ventas', 'TI', 'RRHH', 'Ventas', 'Finanzas', 'TI', 'RRHH', 'Finanzas', 'TI', 'Ventas'],\n",
        "    'Salario': [50000, 60000, 55000, 45000, 70000, 75000, 52000, 58000, 62000, 48000]\n",
        "}\n",
        "\n",
        "# Crear el DataFrame a partir del diccionario\n",
        "data_frame = pd.DataFrame(datos)\n",
        "\n",
        "# Mostrar el DataFrame\n",
        "display(data_frame)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "np4uwoW3Zm9I",
        "outputId": "0f3e0911-0103-423e-8d0b-2fb14974de68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Empleados mayores de 30 a√±os:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Nombre</th>\n",
              "      <th>Edad</th>\n",
              "      <th>Departamento</th>\n",
              "      <th>Salario</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Elena</td>\n",
              "      <td>35</td>\n",
              "      <td>Finanzas</td>\n",
              "      <td>70000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Pedro</td>\n",
              "      <td>40</td>\n",
              "      <td>TI</td>\n",
              "      <td>75000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Miguel</td>\n",
              "      <td>31</td>\n",
              "      <td>TI</td>\n",
              "      <td>62000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Nombre  Edad Departamento  Salario\n",
              "4   Elena    35     Finanzas    70000\n",
              "5   Pedro    40           TI    75000\n",
              "8  Miguel    31           TI    62000"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Salario promedio por departamento:\n",
            "Departamento\n",
            "Finanzas    64000.000000\n",
            "RRHH        53500.000000\n",
            "TI          65666.666667\n",
            "Ventas      47666.666667\n",
            "Name: Salario, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Filtrar empleados mayores de 30 a√±os\n",
        "empleados_mayores = data_frame[data_frame['Edad'] > 30]\n",
        "print(\"\\nEmpleados mayores de 30 a√±os:\")\n",
        "display(empleados_mayores)\n",
        "\n",
        "# Calcular el salario promedio por departamento\n",
        "salario_promedio_por_departamento = data_frame.groupby('Departamento')['Salario'].mean()\n",
        "print(\"\\nSalario promedio por departamento:\")\n",
        "print(salario_promedio_por_departamento)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbpDBXA_YXpX"
      },
      "source": [
        "`chunksize` es un par√°metro que se utiliza en pandas al leer grandes conjuntos de datos desde archivos, como CSV o bases de datos, para dividir el proceso de lectura en fragmentos m√°s peque√±os. Esto es especialmente √∫til cuando el conjunto de datos no cabe completamente en la memoria y deseas procesar los datos en partes m√°s manejables.\n",
        "\n",
        "Cuando se utiliza el par√°metro `chunksize`, pandas lee y procesa el archivo en bloques de tama√±o especificado en lugar de cargar todo el archivo de una vez. Cada bloque se trata como un DataFrame independiente que puedes procesar individualmente o combinar con otros bloques seg√∫n tus necesidades.\n",
        "\n",
        "Aqu√≠ tienes un ejemplo de c√≥mo usar `chunksize` al leer un archivo CSV con pandas:\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Especifica el tama√±o del chunk\n",
        "tama√±o_chunk = 10000\n",
        "\n",
        "# Lee el archivo CSV en bloques de tama√±o_chunk\n",
        "for chunk in pd.read_csv('archivo.csv', chunksize=tama√±o_chunk):\n",
        "    # Realiza operaciones en el chunk actual\n",
        "    # Por ejemplo, puedes realizar c√°lculos o filtrar datos en cada chunk\n",
        "    print(chunk.shape)\n",
        "```\n",
        "\n",
        "En este ejemplo, el archivo CSV se leer√° en bloques de 10,000 filas cada uno. Dentro del bucle `for`, puedes realizar cualquier operaci√≥n que necesites en cada chunk individual.\n",
        "\n",
        "El uso de `chunksize` es √∫til cuando trabajas con conjuntos de datos muy grandes y deseas procesarlos de manera eficiente y sin agotar la memoria disponible. Puedes aplicar funciones, filtros y otras operaciones en cada chunk y luego combinar los resultados seg√∫n sea necesario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUaHQh9IZ18y",
        "outputId": "14ef8b77-1b2a-46d6-919a-0bde261e53e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(100000, 8)\n",
            "(100000, 8)\n",
            "(100000, 8)\n",
            "(100000, 8)\n",
            "(100000, 8)\n",
            "(46212, 8)\n"
          ]
        }
      ],
      "source": [
        "for chunk in pd.read_csv('https://raw.githubusercontent.com/jazaineam1/BigData2023_2/main/Datos/datos_icfes.csv',encoding='latin-1', chunksize=100000):\n",
        "    # Realiza operaciones en el chunk actual\n",
        "    # Por ejemplo, puedes realizar c√°lculos o filtrar datos en cada chunk\n",
        "    print(chunk.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lBb-Nk0YXDz",
        "outputId": "94ff6bcb-09c6-4365-c3c8-d440608425e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "435 ms ¬± 36.1 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "df_icfes=pd.read_csv('https://raw.githubusercontent.com/jazaineam1/BigData2023_2/main/Datos/datos_icfes.csv',encoding='latin-1',chunksize=10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaeUXmKJLwmP",
        "outputId": "4b60410f-ad1d-40b0-e10c-030dc627a3b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "834 ms ¬± 55.3 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "df2=pd.read_csv('https://raw.githubusercontent.com/jazaineam1/BigData2023_2/main/Datos/datos_icfes.csv',encoding='latin-1')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tk4nYDhNaWWy"
      },
      "source": [
        "`pandarallel` es una biblioteca de Python que permite paralelizar operaciones en pandas utilizando m√∫ltiples n√∫cleos de CPU, lo que puede mejorar significativamente el rendimiento en operaciones que involucran grandes conjuntos de datos. A continuaci√≥n, te explicar√© c√≥mo funciona `pandarallel`:\n",
        "\n",
        "1. **Instalaci√≥n:** Primero, debes instalar la biblioteca `pandarallel`. Puedes hacerlo usando el comando pip:\n",
        "\n",
        "   ```\n",
        "   pip install pandarallel\n",
        "   ```\n",
        "\n",
        "2. **Importar y Configurar:** Despu√©s de instalar la biblioteca, debes importarla y configurarla antes de usarla. La configuraci√≥n implica establecer el n√∫mero de n√∫cleos que deseas utilizar para las operaciones paralelas. Aqu√≠ hay un ejemplo de c√≥mo hacerlo:\n",
        "\n",
        "   ```python\n",
        "   from pandarallel import pandarallel\n",
        "\n",
        "   pandarallel.initialize(nb_workers=4)  # N√∫mero de n√∫cleos a utilizar\n",
        "   ```\n",
        "\n",
        "3. **Uso en Operaciones:** Una vez que la biblioteca est√° configurada, puedes usarla en operaciones de pandas. La forma de usar `pandarallel` es utilizando el m√©todo `.parallel_apply()` en Series o DataFrames. Por ejemplo, supongamos que tienes un DataFrame `df` y deseas aplicar una funci√≥n a una columna llamada 'columna_a':\n",
        "\n",
        "   ```python\n",
        "   def mi_funcion(valor):\n",
        "       # Operaciones que deseas realizar en paralelo\n",
        "       return resultado\n",
        "\n",
        "   df['nueva_columna'] = df['columna_a'].parallel_apply(mi_funcion)\n",
        "   ```\n",
        "\n",
        "   El m√©todo `.parallel_apply()` distribuir√° autom√°ticamente la aplicaci√≥n de la funci√≥n en paralelo en los n√∫cleos que hayas configurado previamente.\n",
        "\n",
        "Recuerda que no todas las operaciones se benefician de la paralelizaci√≥n. Operaciones intensivas en c√°lculos o transformaciones suelen ser las m√°s adecuadas para utilizar `pandarallel`.\n",
        "\n",
        "Es importante tener en cuenta que `pandarallel` utiliza la biblioteca `multiprocessing` internamente para lograr la paralelizaci√≥n. Sin embargo, la paralelizaci√≥n introduce cierto overhead, por lo que en operaciones peque√±as podr√≠a no resultar en una mejora significativa de rendimiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKU8jj9aacOY",
        "outputId": "e725a753-be0f-49ed-bff6-c83186bcb212"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandarallel in c:\\users\\ser_s\\anaconda3\\envs\\big_data_env\\lib\\site-packages (1.6.5)\n",
            "Requirement already satisfied: dill>=0.3.1 in c:\\users\\ser_s\\anaconda3\\envs\\big_data_env\\lib\\site-packages (from pandarallel) (0.4.1)\n",
            "Requirement already satisfied: pandas>=1 in c:\\users\\ser_s\\anaconda3\\envs\\big_data_env\\lib\\site-packages (from pandarallel) (3.0.0)\n",
            "Requirement already satisfied: psutil in c:\\users\\ser_s\\anaconda3\\envs\\big_data_env\\lib\\site-packages (from pandarallel) (7.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\ser_s\\anaconda3\\envs\\big_data_env\\lib\\site-packages (from pandas>=1->pandarallel) (2.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ser_s\\anaconda3\\envs\\big_data_env\\lib\\site-packages (from pandas>=1->pandarallel) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata in c:\\users\\ser_s\\anaconda3\\envs\\big_data_env\\lib\\site-packages (from pandas>=1->pandarallel) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\ser_s\\anaconda3\\envs\\big_data_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1->pandarallel) (1.17.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install pandarallel\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGNdrLa0alL4",
        "outputId": "769345c5-e3d3-444e-e0b4-fa492d915491"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO: Pandarallel will run on 3 workers.\n",
            "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
            "\n",
            "WARNING: You are on Windows. If you detect any issue with pandarallel, be sure you checked out the Troubleshooting page:\n",
            "https://nalepae.github.io/pandarallel/troubleshooting/\n"
          ]
        }
      ],
      "source": [
        "from pandarallel import pandarallel\n",
        "\n",
        "pandarallel.initialize(nb_workers=3)  # N√∫mero de n√∫cleos a utilizar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvfx-SJIaqk_",
        "outputId": "c7cd75fa-17c3-4a90-9ed5-f53b06616cc2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<pandas.io.parsers.readers.TextFileReader at 0x214bec7b8d0>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_icfes=pd.read_csv('https://raw.githubusercontent.com/jazaineam1/BigData2023_2/main/Datos/datos_icfes.csv',encoding='latin-1',chunksize=10000)\n",
        "df_icfes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "iBPRAcRQcBmZ",
        "outputId": "961aa26d-1821-4976-d25f-341bc08338f4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ESTU_DEPTO_RESIDE</th>\n",
              "      <th>FAMI_ESTRATOVIVIENDA</th>\n",
              "      <th>PUNT_LECTURA_CRITICA</th>\n",
              "      <th>PUNT_MATEMATICAS</th>\n",
              "      <th>PUNT_C_NATURALES</th>\n",
              "      <th>PUNT_SOCIALES_CIUDADANAS</th>\n",
              "      <th>PUNT_INGLES</th>\n",
              "      <th>PUNT_GLOBAL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MAGDALENA</td>\n",
              "      <td>Estrato 3</td>\n",
              "      <td>47</td>\n",
              "      <td>48</td>\n",
              "      <td>37</td>\n",
              "      <td>30</td>\n",
              "      <td>54</td>\n",
              "      <td>208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BOGOT√Å</td>\n",
              "      <td>Estrato 3</td>\n",
              "      <td>60</td>\n",
              "      <td>65</td>\n",
              "      <td>54</td>\n",
              "      <td>59</td>\n",
              "      <td>63</td>\n",
              "      <td>299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BOLIVAR</td>\n",
              "      <td>Estrato 1</td>\n",
              "      <td>66</td>\n",
              "      <td>57</td>\n",
              "      <td>41</td>\n",
              "      <td>74</td>\n",
              "      <td>64</td>\n",
              "      <td>299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BOGOT√Å</td>\n",
              "      <td>Estrato 3</td>\n",
              "      <td>62</td>\n",
              "      <td>54</td>\n",
              "      <td>61</td>\n",
              "      <td>73</td>\n",
              "      <td>53</td>\n",
              "      <td>309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>BOGOT√Å</td>\n",
              "      <td>Estrato 3</td>\n",
              "      <td>63</td>\n",
              "      <td>57</td>\n",
              "      <td>55</td>\n",
              "      <td>57</td>\n",
              "      <td>52</td>\n",
              "      <td>288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>SUCRE</td>\n",
              "      <td>Estrato 1</td>\n",
              "      <td>42</td>\n",
              "      <td>47</td>\n",
              "      <td>50</td>\n",
              "      <td>39</td>\n",
              "      <td>38</td>\n",
              "      <td>220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>META</td>\n",
              "      <td>Estrato 3</td>\n",
              "      <td>62</td>\n",
              "      <td>65</td>\n",
              "      <td>50</td>\n",
              "      <td>46</td>\n",
              "      <td>45</td>\n",
              "      <td>275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>CUNDINAMARCA</td>\n",
              "      <td>Estrato 2</td>\n",
              "      <td>52</td>\n",
              "      <td>28</td>\n",
              "      <td>45</td>\n",
              "      <td>42</td>\n",
              "      <td>25</td>\n",
              "      <td>202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>SANTANDER</td>\n",
              "      <td>Estrato 1</td>\n",
              "      <td>60</td>\n",
              "      <td>61</td>\n",
              "      <td>55</td>\n",
              "      <td>51</td>\n",
              "      <td>48</td>\n",
              "      <td>280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>BOLIVAR</td>\n",
              "      <td>Estrato 1</td>\n",
              "      <td>58</td>\n",
              "      <td>48</td>\n",
              "      <td>44</td>\n",
              "      <td>33</td>\n",
              "      <td>29</td>\n",
              "      <td>222</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows √ó 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   ESTU_DEPTO_RESIDE FAMI_ESTRATOVIVIENDA  PUNT_LECTURA_CRITICA  \\\n",
              "0          MAGDALENA            Estrato 3                    47   \n",
              "1             BOGOT√Å            Estrato 3                    60   \n",
              "2            BOLIVAR            Estrato 1                    66   \n",
              "3             BOGOT√Å            Estrato 3                    62   \n",
              "4             BOGOT√Å            Estrato 3                    63   \n",
              "..               ...                  ...                   ...   \n",
              "95             SUCRE            Estrato 1                    42   \n",
              "96              META            Estrato 3                    62   \n",
              "97      CUNDINAMARCA            Estrato 2                    52   \n",
              "98         SANTANDER            Estrato 1                    60   \n",
              "99           BOLIVAR            Estrato 1                    58   \n",
              "\n",
              "    PUNT_MATEMATICAS  PUNT_C_NATURALES  PUNT_SOCIALES_CIUDADANAS  PUNT_INGLES  \\\n",
              "0                 48                37                        30           54   \n",
              "1                 65                54                        59           63   \n",
              "2                 57                41                        74           64   \n",
              "3                 54                61                        73           53   \n",
              "4                 57                55                        57           52   \n",
              "..               ...               ...                       ...          ...   \n",
              "95                47                50                        39           38   \n",
              "96                65                50                        46           45   \n",
              "97                28                45                        42           25   \n",
              "98                61                55                        51           48   \n",
              "99                48                44                        33           29   \n",
              "\n",
              "    PUNT_GLOBAL  \n",
              "0           208  \n",
              "1           299  \n",
              "2           299  \n",
              "3           309  \n",
              "4           288  \n",
              "..          ...  \n",
              "95          220  \n",
              "96          275  \n",
              "97          202  \n",
              "98          280  \n",
              "99          222  \n",
              "\n",
              "[100 rows x 8 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_icfes.get_chunk(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3dTJXd9ebitK"
      },
      "outputs": [],
      "source": [
        "df = pd.concat(df_icfes, ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "UWWuRzC9bsPg",
        "outputId": "dd6ab49c-0727-4f5a-8d44-304921aaf642"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ESTU_DEPTO_RESIDE</th>\n",
              "      <th>FAMI_ESTRATOVIVIENDA</th>\n",
              "      <th>PUNT_LECTURA_CRITICA</th>\n",
              "      <th>PUNT_MATEMATICAS</th>\n",
              "      <th>PUNT_C_NATURALES</th>\n",
              "      <th>PUNT_SOCIALES_CIUDADANAS</th>\n",
              "      <th>PUNT_INGLES</th>\n",
              "      <th>PUNT_GLOBAL</th>\n",
              "      <th>PUNT_LECTURA_CRITICA2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CORDOBA</td>\n",
              "      <td>Estrato 2</td>\n",
              "      <td>44</td>\n",
              "      <td>36</td>\n",
              "      <td>41</td>\n",
              "      <td>37</td>\n",
              "      <td>40.0</td>\n",
              "      <td>198</td>\n",
              "      <td>1936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CAUCA</td>\n",
              "      <td>-</td>\n",
              "      <td>32</td>\n",
              "      <td>28</td>\n",
              "      <td>29</td>\n",
              "      <td>32</td>\n",
              "      <td>28.0</td>\n",
              "      <td>150</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BOLIVAR</td>\n",
              "      <td>Estrato 3</td>\n",
              "      <td>40</td>\n",
              "      <td>54</td>\n",
              "      <td>46</td>\n",
              "      <td>42</td>\n",
              "      <td>40.0</td>\n",
              "      <td>225</td>\n",
              "      <td>1600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SUCRE</td>\n",
              "      <td>Estrato 2</td>\n",
              "      <td>39</td>\n",
              "      <td>48</td>\n",
              "      <td>35</td>\n",
              "      <td>31</td>\n",
              "      <td>45.0</td>\n",
              "      <td>194</td>\n",
              "      <td>1521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>BOLIVAR</td>\n",
              "      <td>Estrato 2</td>\n",
              "      <td>43</td>\n",
              "      <td>51</td>\n",
              "      <td>43</td>\n",
              "      <td>44</td>\n",
              "      <td>29.0</td>\n",
              "      <td>220</td>\n",
              "      <td>1849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>546107</th>\n",
              "      <td>ANTIOQUIA</td>\n",
              "      <td>Estrato 2</td>\n",
              "      <td>76</td>\n",
              "      <td>78</td>\n",
              "      <td>65</td>\n",
              "      <td>74</td>\n",
              "      <td>58.0</td>\n",
              "      <td>360</td>\n",
              "      <td>5776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>546108</th>\n",
              "      <td>BOGOT√Å</td>\n",
              "      <td>Estrato 3</td>\n",
              "      <td>75</td>\n",
              "      <td>73</td>\n",
              "      <td>72</td>\n",
              "      <td>67</td>\n",
              "      <td>74.0</td>\n",
              "      <td>360</td>\n",
              "      <td>5625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>546109</th>\n",
              "      <td>ARAUCA</td>\n",
              "      <td>Estrato 2</td>\n",
              "      <td>72</td>\n",
              "      <td>83</td>\n",
              "      <td>71</td>\n",
              "      <td>77</td>\n",
              "      <td>72.0</td>\n",
              "      <td>377</td>\n",
              "      <td>5184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>546110</th>\n",
              "      <td>SANTANDER</td>\n",
              "      <td>Estrato 1</td>\n",
              "      <td>59</td>\n",
              "      <td>61</td>\n",
              "      <td>54</td>\n",
              "      <td>52</td>\n",
              "      <td>46.0</td>\n",
              "      <td>278</td>\n",
              "      <td>3481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>546111</th>\n",
              "      <td>BOGOT√Å</td>\n",
              "      <td>Estrato 3</td>\n",
              "      <td>76</td>\n",
              "      <td>73</td>\n",
              "      <td>72</td>\n",
              "      <td>71</td>\n",
              "      <td>74.0</td>\n",
              "      <td>365</td>\n",
              "      <td>5776</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>546112 rows √ó 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       ESTU_DEPTO_RESIDE FAMI_ESTRATOVIVIENDA  PUNT_LECTURA_CRITICA  \\\n",
              "0                CORDOBA            Estrato 2                    44   \n",
              "1                  CAUCA                    -                    32   \n",
              "2                BOLIVAR            Estrato 3                    40   \n",
              "3                  SUCRE            Estrato 2                    39   \n",
              "4                BOLIVAR            Estrato 2                    43   \n",
              "...                  ...                  ...                   ...   \n",
              "546107         ANTIOQUIA            Estrato 2                    76   \n",
              "546108            BOGOT√Å            Estrato 3                    75   \n",
              "546109            ARAUCA            Estrato 2                    72   \n",
              "546110         SANTANDER            Estrato 1                    59   \n",
              "546111            BOGOT√Å            Estrato 3                    76   \n",
              "\n",
              "        PUNT_MATEMATICAS  PUNT_C_NATURALES  PUNT_SOCIALES_CIUDADANAS  \\\n",
              "0                     36                41                        37   \n",
              "1                     28                29                        32   \n",
              "2                     54                46                        42   \n",
              "3                     48                35                        31   \n",
              "4                     51                43                        44   \n",
              "...                  ...               ...                       ...   \n",
              "546107                78                65                        74   \n",
              "546108                73                72                        67   \n",
              "546109                83                71                        77   \n",
              "546110                61                54                        52   \n",
              "546111                73                72                        71   \n",
              "\n",
              "        PUNT_INGLES  PUNT_GLOBAL  PUNT_LECTURA_CRITICA2  \n",
              "0              40.0          198                   1936  \n",
              "1              28.0          150                   1024  \n",
              "2              40.0          225                   1600  \n",
              "3              45.0          194                   1521  \n",
              "4              29.0          220                   1849  \n",
              "...             ...          ...                    ...  \n",
              "546107         58.0          360                   5776  \n",
              "546108         74.0          360                   5625  \n",
              "546109         72.0          377                   5184  \n",
              "546110         46.0          278                   3481  \n",
              "546111         74.0          365                   5776  \n",
              "\n",
              "[546112 rows x 9 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def cuadrado(valor):\n",
        "    # Operaciones que deseas realizar en paralelo\n",
        "    return valor**2\n",
        "\n",
        "df['PUNT_LECTURA_CRITICA2'] = df['PUNT_LECTURA_CRITICA'].parallel_apply(cuadrado)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zic0il4achHw"
      },
      "source": [
        "#### [PandasAI](https://pandas-ai.readthedocs.io/en/latest/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiIFx9rmcquC",
        "outputId": "3002606a-ef16-4472-aeaa-4507eadfef29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|    | ESTU_DEPTO_RESIDE   | FAMI_ESTRATOVIVIENDA   |   PUNT_LECTURA_CRITICA |   PUNT_MATEMATICAS |   PUNT_C_NATURALES |   PUNT_SOCIALES_CIUDADANAS |   PUNT_INGLES |   PUNT_GLOBAL |   PUNT_LECTURA_CRITICA2 |\n",
            "|---:|:--------------------|:-----------------------|-----------------------:|-------------------:|-------------------:|---------------------------:|--------------:|--------------:|------------------------:|\n",
            "|  0 | CORDOBA             | Estrato 2              |                     44 |                 36 |                 41 |                         37 |            40 |           198 |                    1936 |\n",
            "|  1 | CAUCA               | -                      |                     32 |                 28 |                 29 |                         32 |            28 |           150 |                    1024 |\n",
            "|  2 | BOLIVAR             | Estrato 3              |                     40 |                 54 |                 46 |                         42 |            40 |           225 |                    1600 |\n",
            "|  3 | SUCRE               | Estrato 2              |                     39 |                 48 |                 35 |                         31 |            45 |           194 |                    1521 |\n",
            "|  4 | BOLIVAR             | Estrato 2              |                     43 |                 51 |                 43 |                         44 |            29 |           220 |                    1849 |\n"
          ]
        }
      ],
      "source": [
        "print(df.head(5).to_markdown())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxIecyyVee36"
      },
      "source": [
        "#### **Datos semi estructurados**\n",
        "\n",
        "\n",
        "\n",
        "**1. Identificaci√≥n del formato:** Primero, determina el formato en el que est√°n los datos semiestructurados, ya sea JSON, XML, HTML, CSV, etc. Esto te ayudar√° a elegir la herramienta o biblioteca adecuada para la lectura y an√°lisis.\n",
        "\n",
        "**2. Selecci√≥n de herramientas:** Utiliza bibliotecas o herramientas que sean compatibles con el formato de los datos. Por ejemplo, si tienes datos en formato JSON, puedes utilizar bibliotecas como `json` en Python, si son XML, puedes utilizar `xml.etree.ElementTree`.\n",
        "\n",
        "**3. Lectura de datos:** Utiliza las bibliotecas adecuadas para cargar los datos en una estructura que puedas manipular. Por ejemplo, en Python, puedes cargar datos JSON usando el m√≥dulo `json` o datos XML usando `xml.etree.ElementTree`.\n",
        "\n",
        "**4. Transformaci√≥n y limpieza:** Los datos semiestructurados pueden tener campos opcionales, anidamientos y otros elementos que no siguen una estructura uniforme. Debes realizar una transformaci√≥n y limpieza para estructurar los datos de manera coherente y prepararlos para el an√°lisis.\n",
        "\n",
        "**5. Extracci√≥n de informaci√≥n:** Identifica los campos y elementos relevantes para tu an√°lisis. Puedes acceder a estos campos utilizando las funciones o m√©todos proporcionados por las bibliotecas de lectura correspondientes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2xl5_jwets7"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "data = [\n",
        "    {\n",
        "        \"nombre\": \"Juan\",\n",
        "        \"apellido\": \"P√©rez\",\n",
        "        \"edad\": 28,\n",
        "        \"departamento\": \"Ventas\"\n",
        "    },\n",
        "    {\n",
        "        \"nombre\": \"Mar√≠a\",\n",
        "        \"apellido\": \"G√≥mez\",\n",
        "        \"edad\": 32,\n",
        "        \"departamento\": \"Desarrollo\"\n",
        "    },\n",
        "    {\n",
        "        \"nombre\": \"Carlos\",\n",
        "        \"apellido\": \"L√≥pez\",\n",
        "        \"edad\": 24,\n",
        "        \"departamento\": \"Marketing\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Escribir los datos en un archivo JSON\n",
        "with open(\"empleados.json\", \"w\") as json_file:\n",
        "    json.dump(data, json_file, indent=4)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XC6ZxHxffLU9",
        "outputId": "57110538-265a-4bed-d19c-a9516a030dd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'nombre': 'Juan', 'apellido': 'P√©rez', 'edad': 28, 'departamento': 'Ventas'}, {'nombre': 'Mar√≠a', 'apellido': 'G√≥mez', 'edad': 32, 'departamento': 'Desarrollo'}, {'nombre': 'Carlos', 'apellido': 'L√≥pez', 'edad': 24, 'departamento': 'Marketing'}]\n",
            "Nombre: Juan\n",
            "Apellido: P√©rez\n",
            "Edad: 28\n",
            "Departamento: Ventas\n",
            "\n",
            "Nombre: Mar√≠a\n",
            "Apellido: G√≥mez\n",
            "Edad: 32\n",
            "Departamento: Desarrollo\n",
            "\n",
            "Nombre: Carlos\n",
            "Apellido: L√≥pez\n",
            "Edad: 24\n",
            "Departamento: Marketing\n",
            "\n"
          ]
        }
      ],
      "source": [
        "with open(\"empleados.json\", \"r\") as json_file:\n",
        "    data = json.load(json_file)\n",
        "# Imprimir los datos cargados\n",
        "print(data)\n",
        "\n",
        "# Acceder a la informaci√≥n de cada empleado\n",
        "for empleado in data:\n",
        "    print(\"Nombre:\", empleado[\"nombre\"])\n",
        "    print(\"Apellido:\", empleado[\"apellido\"])\n",
        "    print(\"Edad:\", empleado[\"edad\"])\n",
        "    print(\"Departamento:\", empleado[\"departamento\"])\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oHCiFZWfXdw",
        "outputId": "620e5332-d515-494e-cc39-0b12258193e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Edad promedio: 28.0\n",
            "Conteo de empleados por departamento: {'Ventas': 1, 'Marketing': 1, 'Desarrollo': 1}\n"
          ]
        }
      ],
      "source": [
        "# Calcular la edad promedio de los empleados\n",
        "edades = [empleado[\"edad\"] for empleado in data]\n",
        "edad_promedio = sum(edades) / len(edades)\n",
        "print(\"Edad promedio:\", edad_promedio)\n",
        "\n",
        "# Contar el n√∫mero de empleados por departamento\n",
        "departamentos = [empleado[\"departamento\"] for empleado in data]\n",
        "departamento_contadores = {departamento: departamentos.count(departamento) for departamento in set(departamentos)}\n",
        "print(\"Conteo de empleados por departamento:\", departamento_contadores)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "ONE2PAwDfhsN",
        "outputId": "93437600-69b1-473f-f301-4b314b335b33"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nombre</th>\n",
              "      <th>apellido</th>\n",
              "      <th>edad</th>\n",
              "      <th>departamento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Juan</td>\n",
              "      <td>P√©rez</td>\n",
              "      <td>28</td>\n",
              "      <td>Ventas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mar√≠a</td>\n",
              "      <td>G√≥mez</td>\n",
              "      <td>32</td>\n",
              "      <td>Desarrollo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Carlos</td>\n",
              "      <td>L√≥pez</td>\n",
              "      <td>24</td>\n",
              "      <td>Marketing</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   nombre apellido  edad departamento\n",
              "0    Juan    P√©rez    28       Ventas\n",
              "1   Mar√≠a    G√≥mez    32   Desarrollo\n",
              "2  Carlos    L√≥pez    24    Marketing"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2 = pd.DataFrame(data)\n",
        "df2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzfUeKFKf4EC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "# Generar datos de empleados\n",
        "data = [\n",
        "    {\n",
        "        \"nombre\": \"Juan\",\n",
        "        \"apellido\": \"P√©rez\",\n",
        "        \"edad\": 28,\n",
        "        \"departamento\": \"Ventas\"\n",
        "    },\n",
        "    {\n",
        "        \"nombre\": \"Mar√≠a\",\n",
        "        \"apellido\": \"G√≥mez\",\n",
        "        \"edad\": 32,\n",
        "        \"departamento\": \"Desarrollo\"\n",
        "    },\n",
        "    {\n",
        "        \"nombre\": \"Carlos\",\n",
        "        \"apellido\": \"L√≥pez\",\n",
        "        \"edad\": 24,\n",
        "        \"departamento\": \"Marketing\"\n",
        "    },\n",
        "    {\n",
        "        \"nombre\": \"Ana\",\n",
        "        \"apellido\": \"Mart√≠nez\",\n",
        "        \"edad\": 30,\n",
        "        \"departamento\": \"Recursos Humanos\"\n",
        "    },\n",
        "    {\n",
        "        \"nombre\": \"Luis\",\n",
        "        \"apellido\": \"Rodr√≠guez\",\n",
        "        \"edad\": 29,\n",
        "        \"departamento\": \"Ventas\"\n",
        "    },\n",
        "    {\n",
        "        \"nombre\": \"Laura\",\n",
        "        \"apellido\": \"S√°nchez\",\n",
        "        \"edad\": 28,\n",
        "        \"departamento\": \"Desarrollo\"\n",
        "    },\n",
        "    {\n",
        "        \"nombre\": \"Pedro\",\n",
        "        \"apellido\": \"Gonz√°lez\",\n",
        "        \"edad\": 26,\n",
        "        \"departamento\": \"Marketing\"\n",
        "    },\n",
        "    {\n",
        "        \"nombre\": \"Sof√≠a\",\n",
        "        \"apellido\": \"L√≥pez\",\n",
        "        \"edad\": 27,\n",
        "        \"departamento\": \"Ventas\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Crear el elemento ra√≠z del XML\n",
        "root = ET.Element(\"empleados\")\n",
        "\n",
        "# Iterar a trav√©s de los datos y agregar elementos al XML\n",
        "for empleado_data in data:\n",
        "    empleado = ET.SubElement(root, \"empleado\")\n",
        "    for clave, valor in empleado_data.items():\n",
        "        ET.SubElement(empleado, clave).text = str(valor)\n",
        "\n",
        "# Crear el √°rbol XML\n",
        "tree = ET.ElementTree(root)\n",
        "\n",
        "# Escribir el √°rbol XML en un archivo\n",
        "tree.write(\"empleados.xml\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GSVDXBqgZGd",
        "outputId": "5fc19f55-4fdb-401d-db1c-f7a4805b1aba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Informaci√≥n b√°sica del DataFrame:\n",
            "<class 'pandas.DataFrame'>\n",
            "RangeIndex: 8 entries, 0 to 7\n",
            "Data columns (total 4 columns):\n",
            " #   Column        Non-Null Count  Dtype\n",
            "---  ------        --------------  -----\n",
            " 0   nombre        8 non-null      str  \n",
            " 1   apellido      8 non-null      str  \n",
            " 2   edad          8 non-null      int64\n",
            " 3   departamento  8 non-null      str  \n",
            "dtypes: int64(1), str(3)\n",
            "memory usage: 388.0 bytes\n",
            "None\n",
            "\n",
            "Edad promedio por departamento:\n",
            "departamento\n",
            "Desarrollo          30.0\n",
            "Marketing           25.0\n",
            "Recursos Humanos    30.0\n",
            "Ventas              28.0\n",
            "Name: edad, dtype: float64\n",
            "\n",
            "Conteo de empleados por departamento:\n",
            "departamento\n",
            "Ventas              3\n",
            "Desarrollo          2\n",
            "Marketing           2\n",
            "Recursos Humanos    1\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "# Parsear el archivo XML\n",
        "tree = ET.parse(\"empleados.xml\")\n",
        "root = tree.getroot()\n",
        "\n",
        "# Crear una lista para almacenar los datos\n",
        "data = []\n",
        "\n",
        "# Iterar a trav√©s de los elementos del XML\n",
        "for empleado in root.findall(\"empleado\"):\n",
        "    nombre = empleado.find(\"nombre\").text\n",
        "    apellido = empleado.find(\"apellido\").text\n",
        "    edad = int(empleado.find(\"edad\").text)\n",
        "    departamento = empleado.find(\"departamento\").text\n",
        "    data.append({\"nombre\": nombre, \"apellido\": apellido, \"edad\": edad, \"departamento\": departamento})\n",
        "\n",
        "# Convertir la lista de datos a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Mostrar informaci√≥n b√°sica del DataFrame\n",
        "print(\"Informaci√≥n b√°sica del DataFrame:\")\n",
        "print(df.info())\n",
        "\n",
        "# An√°lisis de edad promedio por departamento\n",
        "edad_promedio_por_departamento = df.groupby(\"departamento\")[\"edad\"].mean()\n",
        "print(\"\\nEdad promedio por departamento:\")\n",
        "print(edad_promedio_por_departamento)\n",
        "\n",
        "# An√°lisis de la distribuci√≥n de departamentos\n",
        "conteo_departamentos = df[\"departamento\"].value_counts()\n",
        "print(\"\\nConteo de empleados por departamento:\")\n",
        "print(conteo_departamentos)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNnQY5GBgxTh"
      },
      "source": [
        "#### Datos no estructurados\n",
        "\n",
        "\n",
        "\n",
        "**1. Preprocesamiento de datos:**\n",
        "   - Limpieza: Eliminar ruido y datos irrelevantes.\n",
        "   - Tokenizaci√≥n: Dividir el texto en unidades m√°s peque√±as (palabras, frases, etc.).\n",
        "   - Normalizaci√≥n: Convertir texto a min√∫sculas, eliminar signos de puntuaci√≥n, etc.\n",
        "   - Eliminaci√≥n de stop words: Eliminar palabras comunes sin significado (por ejemplo, \"el\", \"y\", \"en\").\n",
        "   - Stemming y lematizaci√≥n: Reducir palabras a su forma base.\n",
        "\n",
        "**2. An√°lisis de texto:**\n",
        "   - An√°lisis de sentimiento: Determinar si el texto transmite emociones positivas, negativas o neutrales.\n",
        "   - Extracci√≥n de entidades: Identificar nombres de personas, lugares, fechas, etc.\n",
        "   - Detecci√≥n de temas: Identificar temas clave presentes en el texto.\n",
        "   - Modelado de t√≥picos: Agrupar documentos en temas relacionados.\n",
        "\n",
        "**3. Procesamiento de im√°genes y videos:**\n",
        "   - Extracci√≥n de caracter√≠sticas: Convertir im√°genes en vectores num√©ricos.\n",
        "   - Detecci√≥n de objetos: Identificar y localizar objetos en una imagen.\n",
        "   - Segmentaci√≥n: Dividir una imagen en partes significativas.\n",
        "   - Reconocimiento de patrones: Identificar patrones o formas en las im√°genes.\n",
        "\n",
        "**4. Procesamiento de audio:**\n",
        "   - Extracci√≥n de caracter√≠sticas: Convertir se√±ales de audio en datos num√©ricos.\n",
        "   - Detecci√≥n de voz: Identificar partes habladas en una grabaci√≥n de audio.\n",
        "   - Reconocimiento de habla: Convertir el habla en texto escrito.\n",
        "\n",
        "**5. An√°lisis de redes sociales y web:**\n",
        "   - An√°lisis de redes sociales: Examinar patrones de interacci√≥n y opiniones en plataformas sociales.\n",
        "   - Web scraping: Recopilar datos relevantes de sitios web.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytGJMNmGgyUv",
        "outputId": "ffc9e3ff-d3ac-4063-fd0f-a7147fb5261f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Palabras m√°s comunes:\n",
            "la: 19\n",
            "y: 15\n",
            "en: 13\n",
            "de: 10\n",
            "que: 7\n",
            "\n",
            "Total de oraciones: 16\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "texto_largo = \"\"\"\n",
        "La tecnolog√≠a ha revolucionado nuestra sociedad en formas nunca antes imaginadas. La comunicaci√≥n, la informaci√≥n y la forma en que hacemos negocios han experimentado transformaciones radicales.\n",
        "\n",
        "Hoy en d√≠a, los dispositivos m√≥viles son una extensi√≥n de nosotros mismos. Nos conectamos con personas de todo el mundo en un instante y compartimos ideas, im√°genes y momentos a trav√©s de plataformas digitales.\n",
        "\n",
        "La inteligencia artificial est√° en constante evoluci√≥n y desaf√≠a lo que cre√≠amos posible. Desde asistentes virtuales hasta sistemas de recomendaci√≥n en l√≠nea, la IA est√° transformando la manera en que interactuamos con la tecnolog√≠a y c√≥mo vivimos nuestras vidas.\n",
        "\n",
        "Los datos se han convertido en un recurso invaluable. Las empresas recopilan y analizan grandes cantidades de datos para comprender mejor a sus clientes, optimizar operaciones y tomar decisiones informadas. Sin embargo, esta riqueza de datos tambi√©n plantea cuestiones sobre la privacidad y la seguridad.\n",
        "\n",
        "El aprendizaje autom√°tico nos ha brindado herramientas para resolver problemas complejos y hacer predicciones precisas. Los algoritmos pueden detectar patrones en los datos y adaptarse a nuevas situaciones, lo que ha abierto la puerta a aplicaciones en una amplia gama de campos, desde la medicina hasta la conducci√≥n aut√≥noma.\n",
        "\n",
        "A medida que avanzamos en la era digital, es esencial abordar los desaf√≠os √©ticos y sociales que surgen. La adicci√≥n a la tecnolog√≠a, la desinformaci√≥n en l√≠nea y la automatizaci√≥n de trabajos son temas que requieren atenci√≥n cuidadosa y soluciones equitativas.\n",
        "\n",
        "En resumen, la tecnolog√≠a ha transformado nuestro mundo de maneras inimaginables. Si bien ha mejorado muchas √°reas de nuestras vidas, tambi√©n plantea interrogantes y dilemas. Como sociedad, debemos navegar por este nuevo territorio con responsabilidad y consideraci√≥n.\n",
        "\"\"\"\n",
        "\n",
        "# Escribir el texto en un archivo\n",
        "with open(\"texto_largo.txt\", \"w\") as txt_file:\n",
        "    txt_file.write(texto_largo)\n",
        "\n",
        "\n",
        "# Leer el archivo de texto\n",
        "with open(\"texto_largo.txt\", \"r\") as txt_file:\n",
        "    texto = txt_file.read()\n",
        "\n",
        "# Contar palabras usando expresiones regulares\n",
        "palabras = re.findall(r'\\b\\w+\\b', texto.lower())\n",
        "conteo_palabras = Counter(palabras)\n",
        "\n",
        "# Mostrar las palabras m√°s comunes\n",
        "print(\"Palabras m√°s comunes:\")\n",
        "for palabra, conteo in conteo_palabras.most_common(5):\n",
        "    print(f\"{palabra}: {conteo}\")\n",
        "\n",
        "# Contar oraciones\n",
        "oraciones = re.split(r'[.!?]', texto)\n",
        "conteo_oraciones = len([oracion for oracion in oraciones if oracion.strip() != \"\"])\n",
        "\n",
        "# Mostrar el conteo de oraciones\n",
        "print(\"\\nTotal de oraciones:\", conteo_oraciones)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "Douoj9PvhUNX",
        "outputId": "d04a7562-da4d-4c3f-a277-d1776bc881c7"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'matplotlib'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      2\u001b[39m palabras = re.findall(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mb\u001b[39m\u001b[33m'\u001b[39m, texto.lower())\n\u001b[32m      3\u001b[39m conteo_palabras = Counter(palabras)\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "palabras = re.findall(r'\\b\\w+\\b', texto.lower())\n",
        "conteo_palabras = Counter(palabras)\n",
        "\n",
        "# Obtener las palabras m√°s comunes y sus conteos\n",
        "palabras_comunes = [palabra for palabra, conteo in conteo_palabras.most_common(10)]\n",
        "conteos = [conteo_palabras[palabra] for palabra in palabras_comunes]\n",
        "\n",
        "# Crear un gr√°fico de barras\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(palabras_comunes, conteos, color='skyblue')\n",
        "plt.title('Palabras M√°s Comunes en el Texto')\n",
        "plt.xlabel('Palabra')\n",
        "plt.ylabel('Conteo')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Mostrar el gr√°fico\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiJY8D_ziB1Z"
      },
      "source": [
        "**Reto:**  ¬øC√≥mo har√≠as el an√°lsis de este conjunto de [datos](https://www.datos.gov.co/Gastos-Gubernamentales/SECOP-Integrado/rpmr-utcd)?.\n",
        "\n",
        "Pueden revisar informaci√≥n sobre c√≥mo en la p√°gina: https://dev.socrata.com/foundry/www.datos.gov.co/rpmr-utcd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5reKroluA62",
        "outputId": "146615d2-e647-45f1-9a32-e0d51325ec3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "pip install requests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bj0I0K31wFpB"
      },
      "source": [
        "Por supuesto, aqu√≠ tienes un tutorial paso a paso sobre c√≥mo utilizar la API de Socrata con los datos proporcionados, utilizando Python.\n",
        "\n",
        "## Tutorial: Uso de la API Socrata con Python\n",
        "\n",
        "En este tutorial, aprenderemos c√≥mo utilizar la API de Socrata para acceder a los datos del portal \"Datos Abiertos Colombia\". Utilizaremos Python y la biblioteca `requests` para realizar solicitudes a la API y procesar los datos.\n",
        "\n",
        "### Paso 1: Importar las Bibliotecas\n",
        "\n",
        "En primer lugar, asegur√©monos de tener la biblioteca `requests` instalada. Si no lo tienes, puedes instalarla con el siguiente comando:\n",
        "\n",
        "```bash\n",
        "pip install requests\n",
        "```\n",
        "\n",
        "Ahora, en tu script de Python, importa la biblioteca `requests`:\n",
        "\n",
        "```python\n",
        "import requests\n",
        "```\n",
        "\n",
        "### Paso 2: URL de la API\n",
        "\n",
        "Visita el enlace que proporcionaste: [https://www.datos.gov.co/Gastos-Gubernamentales/SECOP-Integrado/rpmr-utcd](https://www.datos.gov.co/Gastos-Gubernamentales/SECOP-Integrado/rpmr-utcd). En la parte superior derecha de la p√°gina, encontrar√°s un bot√≥n que dice \"API\". Haz clic en √©l y copia la URL que aparece en la barra de direcciones.\n",
        "\n",
        "### Paso 3: Realizar una Solicitud a la API\n",
        "\n",
        "Ahora, utilizaremos la URL de la API que copiamos en el paso anterior para hacer una solicitud GET y obtener los datos. Tambi√©n definiremos los par√°metros que queremos incluir en la consulta.\n",
        "\n",
        "```python\n",
        "# URL de la API\n",
        "url = \"https://www.datos.gov.co/resource/rpmr-utcd.json\"\n",
        "\n",
        "# Par√°metros de la consulta\n",
        "params = {\n",
        "    \"$limit\": 10,  # N√∫mero m√°ximo de registros a obtener\n",
        "    \"$offset\": 0,  # √çndice de inicio\n",
        "    \"$select\": \"nombre_de_la_entidad,nit_de_la_entidad,departamento_entidad,valor_contrato\",  # Campos a seleccionar\n",
        "}\n",
        "\n",
        "# Realizar la solicitud GET\n",
        "response = requests.get(url, params=params)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    data = response.json()\n",
        "else:\n",
        "    print(\"Error al acceder a la API:\", response.status_code)\n",
        "    exit()\n",
        "\n",
        "```\n",
        "\n",
        "### Paso 4: Procesar los Datos\n",
        "\n",
        "Ahora que tenemos la respuesta de la API, procesaremos los datos utilizando la biblioteca `json` de Python para convertir la respuesta en un formato legible.\n",
        "\n",
        "```python\n",
        "import json\n",
        "\n",
        "# Convertir la respuesta en formato JSON\n",
        "data = response.json()\n",
        "\n",
        "# Mostrar los primeros registros\n",
        "for item in data:\n",
        "    print(item)\n",
        "```\n",
        "\n",
        "### Paso 5: Analizar y Visualizar los Datos\n",
        "\n",
        "Si deseas realizar an√°lisis m√°s detallados o visualizar los datos, puedes usar bibliotecas como `pandas` o `matplotlib`. Por ejemplo, aqu√≠ hay un ejemplo simple utilizando `pandas` para crear un DataFrame y mostrar los primeros registros:\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Crear un DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Mostrar los primeros registros\n",
        "print(df.head())\n",
        "```\n",
        "\n",
        "Este tutorial te ha guiado a trav√©s de los pasos clave para utilizar la API de Socrata con Python. Puedes personalizar los par√°metros de la consulta seg√∫n tus necesidades y seguir explorando y analizando los datos. ¬°Divi√©rtete explorando y analizando los datos abiertos!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5aPNIcPxCAS"
      },
      "outputs": [],
      "source": [
        "#pruebe este codigo ac√°\n",
        "#realice una visualizaci√≥n de una variable que le resulte interesante\n",
        "#haga un breve an√°lisis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpaeYrS6jGXQ"
      },
      "source": [
        "## Conclusiones\n",
        "\n",
        "Por supuesto, aqu√≠ tienes cinco conclusiones claras y relevantes basadas en la informaci√≥n que proporcionaste:\n",
        "\n",
        "1. **Impacto de la Era de la Informaci√≥n:** En la actual \"Era de la Informaci√≥n\", las empresas deben aprovechar el an√°lisis de big data para tomar decisiones m√°s informadas y estrat√©gicas. La abundancia de datos y la r√°pida evoluci√≥n tecnol√≥gica han transformado la forma en que las organizaciones operan y compiten.\n",
        "\n",
        "2. **Importancia de los Cinco V del Big Data:** La gesti√≥n efectiva del big data requiere abordar los cinco V: volumen, velocidad, variedad, veracidad y valor. Estas caracter√≠sticas distinguen los datos como \"grandes\" y plantean desaf√≠os espec√≠ficos que deben abordarse para aprovechar todo su potencial.\n",
        "\n",
        "3. **Diversidad de Tipos de Datos:** Los datos estructurados, no estructurados y semi-estructurados son fundamentales en el an√°lisis de big data. Comprender estos tipos de datos es esencial para procesarlos eficazmente y extraer conocimientos significativos. Los datos no estructurados, en particular, representan una gran parte del panorama de datos empresariales.\n",
        "\n",
        "4. **Elecci√≥n entre On-Premise y Data Cloud:** Las empresas deben considerar cuidadosamente si optar por soluciones de almacenamiento y procesamiento \"on-premise\" o en la nube. Cada enfoque tiene sus propias ventajas y desaf√≠os en t√©rminos de control, seguridad, escalabilidad y costos, y la elecci√≥n debe basarse en las necesidades y objetivos de la organizaci√≥n.\n",
        "\n",
        "\n",
        "\n",
        "5. **Ingesta de Datos en Python para Diferentes Tipos:** Adem√°s de comprender los tipos de datos, es esencial saber c√≥mo realizar la ingesta de datos en diferentes formatos en Python. Para datos estructurados, semi-estructurados y no estructurados, Python ofrece bibliotecas y herramientas espec√≠ficas que permiten a las empresas extraer, transformar y cargar (ETL) datos de manera eficiente. Explorar y utilizar bibliotecas como pandas, re y json en Python facilita la preparaci√≥n y el procesamiento de datos en diversos formatos, lo que es fundamental para el an√°lisis de big data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJ-H2e16ruKy"
      },
      "source": [
        "# **Ejercicio en tiempo libre:**\n",
        " Fortaleciendo tus Habilidades en Python: Practica Constante\n",
        "\n",
        "## **Acceso a los Recursos**\n",
        "\n",
        "Hemos recopilado una serie de cuadernos de pr√°ctica para ustedes. Pueden acceder a estos recursos en este [enlace](https://github.com/jazaineam1/BigData2023_2/blob/main/Practica%20Python-20230216.zip). ¬°No duden en descargarlos y explorarlos desde donde se encuentren!\n",
        "\n",
        "Recuerden, la pr√°ctica es el camino hacia la maestr√≠a. A medida que se sumerjan en los desaf√≠os y ejercicios de estos cuadernos, ver√°n c√≥mo sus habilidades en Python crecer√°n y se fortalecer√°n."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HENvy16Dj7r3"
      },
      "source": [
        "**Gracias**\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNdPsG8duTOJqVBkBytBylA",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "big_data_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
